{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e178c98-4b46-4238-800f-a0e3538f2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from utils import data_process\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from analysis_utils import *\n",
    "\n",
    "sys.append(\"../\")\n",
    "\n",
    "from get_mlp_mappings import ComputeMLPContributions\n",
    "\n",
    "from cluster_utils.cluster_utils import get_gabor_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"cityscapes\", \"vipseg\"]\n",
    "vidnames = {\"cityscapes\": [\"0005\"], \"vipseg\": [\"26_cblDl5vCZnw\"]}\n",
    "\n",
    "cfg_dict = {}\n",
    "dataloader_dict = {}\n",
    "weights_dict = {}\n",
    "ffn_models_dict = {}\n",
    "categories_dicts = {}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    weights_dict[dataset_name] = {}\n",
    "    cfg_dict[dataset_name] = {}\n",
    "    ffn_models_dict[dataset_name] = {}\n",
    "    categories_dicts[dataset_name] = {}\n",
    "\n",
    "    for vidname in vidnames[dataset_name]:\n",
    "        weights_dict[dataset_name][\n",
    "            vidname\n",
    "        ] = \"path/to/checkpoint\"\n",
    "\n",
    "        cfg, categories_dict = load_cfg(\n",
    "            weights_dict[dataset_name][vidname], dataset_name, vidname\n",
    "        )\n",
    "        cfg_dict[dataset_name][vidname] = cfg\n",
    "        categories_dicts[dataset_name][vidname] = categories_dict\n",
    "\n",
    "        ffn_models_dict[dataset_name][vidname] = load_model(cfg)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    dataloader_dict[dataset_name] = {}\n",
    "    for vidname in vidnames[dataset_name]:\n",
    "        single_image_dataloader = get_loader(\n",
    "            cfg_dict[dataset_name][vidname], dataset_name\n",
    "        )\n",
    "        dataloader_dict[dataset_name][vidname] = single_image_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a57a2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_info(inference_results, object_categories, categories):\n",
    "\n",
    "    inst_id_to_cat_and_inst_suffix = {}\n",
    "    object_to_instances_map = {}\n",
    "    obj_to_obj_name_idx = {}\n",
    "    instance_names = []\n",
    "    object_to_instances_map = defaultdict(list)\n",
    "    instance_to_ann_id_map = {}\n",
    "\n",
    "    for idx, object_cat in enumerate(object_categories):\n",
    "        obj_to_obj_name_idx[object_cat] = idx\n",
    "\n",
    "    # Get annos for current frame\n",
    "    frame_annos = inference_results[\"annotations\"]\n",
    "    for ann in frame_annos:\n",
    "        category_name = [\n",
    "            cat[\"name\"] for cat in categories if cat[\"id\"] == ann[\"category_id\"]\n",
    "        ][0]\n",
    "\n",
    "        num_instances_of_obj = len(object_to_instances_map[category_name])\n",
    "        if ann[\"inst_id\"] not in list(inst_id_to_cat_and_inst_suffix.keys()):\n",
    "            inst_id_to_cat_and_inst_suffix[ann[\"inst_id\"]] = {\n",
    "                \"category\": category_name,\n",
    "                \"inst_suffix\": num_instances_of_obj,\n",
    "                \"instance_name\": category_name + \"_\" + str(num_instances_of_obj),\n",
    "            }\n",
    "\n",
    "        # Retrieve the stored instance name\n",
    "        instance_name = inst_id_to_cat_and_inst_suffix[ann[\"inst_id\"]][\"instance_name\"]\n",
    "        instance_to_ann_id_map[instance_name] = ann[\"id\"]\n",
    "\n",
    "        if instance_name not in instance_names:\n",
    "            object_to_instances_map[category_name].append(instance_name)\n",
    "            instance_names.append(instance_name)\n",
    "\n",
    "    def custom_sort_key(item):\n",
    "        parts = item.split(\"_\")\n",
    "        return (\"_\".join(parts[:-1]), int(parts[-1]))\n",
    "\n",
    "    instance_names = [item for item in sorted(instance_names, key=custom_sort_key)]\n",
    "    instance_names.append(instance_names.pop(instance_names.index(\"other_0\")))\n",
    "\n",
    "    return (\n",
    "        inst_id_to_cat_and_inst_suffix,\n",
    "        instance_to_ann_id_map,\n",
    "        instance_names,\n",
    "        object_to_instances_map,\n",
    "        obj_to_obj_name_idx,\n",
    "        instance_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffc28a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_contribs(\n",
    "    layer_1_output_contrib,\n",
    "    layer_2_output_contrib,\n",
    "    layer_3_output_contrib,\n",
    "    annotations,\n",
    "    instance_to_ann_id_map,\n",
    "    instance_names,\n",
    "):\n",
    "    total_img_area = layer_1_output_contrib.size(-2) * layer_1_output_contrib.size(-1)\n",
    "    num_instances = len(instance_names)\n",
    "    instance_areas = torch.zeros(num_instances)\n",
    "\n",
    "    # Maps for kernel to object contributions\n",
    "    num_layer_1_neurons = layer_1_output_contrib.shape[0]\n",
    "    num_layer_2_neurons = layer_2_output_contrib.shape[0]\n",
    "    num_layer_3_neurons = layer_3_output_contrib.shape[0]\n",
    "    layer_1_to_instance_contribs = torch.zeros((num_layer_1_neurons, num_instances))\n",
    "    layer_2_to_instance_contribs = torch.zeros((num_layer_2_neurons, num_instances))\n",
    "    layer_3_to_instance_contribs = torch.zeros((num_layer_3_neurons, num_instances))\n",
    "\n",
    "    layer_1_instance_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_1_neurons, num_instances)\n",
    "    )\n",
    "    layer_2_instance_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_2_neurons, num_instances)\n",
    "    )\n",
    "    layer_3_instance_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_3_neurons, num_instances)\n",
    "    )\n",
    "\n",
    "    # Store the total neuron-wise contributions to output image\n",
    "    total_layer_1_output_contrib = torch.sum(\n",
    "        torch.abs(layer_1_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_2_output_contrib = torch.sum(\n",
    "        torch.abs(layer_2_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_3_output_contrib = torch.sum(\n",
    "        torch.abs(layer_3_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "\n",
    "    for instance in instance_to_ann_id_map:\n",
    "        ann_id = instance_to_ann_id_map[instance]\n",
    "        ann = [ann for ann in annotations if ann[\"id\"] == ann_id][0]\n",
    "        area = ann[\"area\"]\n",
    "        bimask = ann[\"bimask\"].squeeze()\n",
    "\n",
    "        curr_instance_layer_1_contribs = torch.abs(layer_1_output_contrib[:, bimask])\n",
    "        curr_instance_layer_2_contribs = torch.abs(layer_2_output_contrib[:, bimask])\n",
    "        curr_instance_layer_3_contribs = torch.abs(layer_3_output_contrib[:, bimask])\n",
    "\n",
    "        # Get aggregated total contribution for each kernel to the instance\n",
    "        total_layer_1_inst_contrib = torch.sum(curr_instance_layer_1_contribs, dim=-1)\n",
    "        total_layer_2_inst_contrib = torch.sum(curr_instance_layer_2_contribs, dim=-1)\n",
    "        total_layer_3_inst_contrib = torch.sum(curr_instance_layer_3_contribs, dim=-1)\n",
    "        avg_layer_1_contrib = total_layer_1_inst_contrib / area\n",
    "        avg_layer_2_contrib = total_layer_2_inst_contrib / area\n",
    "        avg_layer_3_contrib = total_layer_3_inst_contrib / area\n",
    "\n",
    "        # Store the average contribution from each layer neurons to current instance\n",
    "        inst_idx = instance_names.index(instance)\n",
    "        layer_1_to_instance_contribs[:, inst_idx] = avg_layer_1_contrib.flatten()\n",
    "        layer_2_to_instance_contribs[:, inst_idx] = avg_layer_2_contrib.flatten()\n",
    "        layer_3_to_instance_contribs[:, inst_idx] = avg_layer_3_contrib.flatten()\n",
    "\n",
    "        # Compute deltas: ( actual contrib - expected contrib ) / expected contrib\n",
    "        layer_1_expected_instance_contrib = total_layer_1_output_contrib * (\n",
    "            area / total_img_area\n",
    "        )\n",
    "        layer_1_instance_contrib_ratio_to_total[:, inst_idx] = (\n",
    "            torch.abs(total_layer_1_inst_contrib - layer_1_expected_instance_contrib)\n",
    "            / layer_1_expected_instance_contrib\n",
    "        )\n",
    "        layer_2_expected_instance_contrib = total_layer_2_output_contrib * (\n",
    "            area / total_img_area\n",
    "        )\n",
    "        layer_2_instance_contrib_ratio_to_total[:, inst_idx] = (\n",
    "            torch.abs(total_layer_2_inst_contrib - layer_2_expected_instance_contrib)\n",
    "            / layer_2_expected_instance_contrib\n",
    "        )\n",
    "        layer_3_expected_instance_contrib = total_layer_3_output_contrib * (\n",
    "            area / total_img_area\n",
    "        )\n",
    "        layer_3_instance_contrib_ratio_to_total[:, inst_idx] = (\n",
    "            torch.abs(total_layer_3_inst_contrib - layer_3_expected_instance_contrib)\n",
    "            / layer_3_expected_instance_contrib\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        layer_1_to_instance_contribs,\n",
    "        layer_2_to_instance_contribs,\n",
    "        layer_3_to_instance_contribs,\n",
    "        layer_1_instance_contrib_ratio_to_total,\n",
    "        layer_2_instance_contrib_ratio_to_total,\n",
    "        layer_3_instance_contrib_ratio_to_total,\n",
    "        instance_areas,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d464f2c-1e3b-45cc-8379-ac823bdbbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridcell_contribs(\n",
    "    layer_1_output_contrib,\n",
    "    layer_2_output_contrib,\n",
    "    layer_3_output_contrib,\n",
    "    reg_stride_h,\n",
    "    reg_stride_w,\n",
    "):\n",
    "    total_img_area = layer_1_output_contrib.size(-2) * layer_1_output_contrib.size(-1)\n",
    "    \n",
    "    unfolded_layer_1_to_gridcell_contribs = (\n",
    "        torch.abs(layer_1_output_contrib)\n",
    "        .unfold(1, reg_stride_h, reg_stride_h)\n",
    "        .unfold(2, reg_stride_w, reg_stride_w)\n",
    "        .permute(0, 3, 4, 1, 2)\n",
    "    ) # num_neurons x cell_stride x cell_stride x h/cell_stride*w/cell_stride\n",
    "    unfolded_layer_2_to_gridcell_contribs = (\n",
    "        torch.abs(layer_2_output_contrib)\n",
    "        .unfold(1, reg_stride_h, reg_stride_h)\n",
    "        .unfold(2, reg_stride_w, reg_stride_w)\n",
    "        .permute(0, 3, 4, 1, 2)\n",
    "    )\n",
    "    unfolded_layer_3_to_gridcell_contribs = (\n",
    "        torch.abs(layer_3_output_contrib)\n",
    "        .unfold(1, reg_stride_h, reg_stride_h)\n",
    "        .unfold(2, reg_stride_w, reg_stride_w)\n",
    "        .permute(0, 3, 4, 1, 2)\n",
    "    )\n",
    "    total_layer_1_output_contrib = torch.sum(\n",
    "        torch.abs(layer_1_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_2_output_contrib = torch.sum(\n",
    "        torch.abs(layer_2_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_3_output_contrib = torch.sum(\n",
    "        torch.abs(layer_3_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "\n",
    "    gridcell_area = unfolded_layer_1_to_gridcell_contribs.size(3) * unfolded_layer_1_to_gridcell_contribs.size(4)\n",
    "\n",
    "    layer_1_to_gridcell_contribs = torch.abs(unfolded_layer_1_to_gridcell_contribs)\n",
    "    layer_2_to_gridcell_contribs = torch.abs(unfolded_layer_2_to_gridcell_contribs)\n",
    "    layer_3_to_gridcell_contribs = torch.abs(unfolded_layer_3_to_gridcell_contribs)\n",
    "\n",
    "    # Flatten contributions by region before taking variance over pixels in region\n",
    "    flattened_layer_1_gridcell_contribs = layer_1_to_gridcell_contribs.flatten(3, 4).flatten(1, 2)\n",
    "    # num_neurons x num_gridcells x h/cell_stride*w/cell_stride\n",
    "    flattened_layer_2_gridcell_contribs = layer_2_to_gridcell_contribs.flatten(3, 4).flatten(1, 2)\n",
    "    flattened_layer_3_gridcell_contribs = layer_3_to_gridcell_contribs.flatten(3, 4).flatten(1, 2)\n",
    "\n",
    "    # Compute deltas: (actual contrib - expected contrib) / expected contrib\n",
    "    layer_1_expected_region_contrib = total_layer_1_output_contrib[:, None] * (\n",
    "        gridcell_area / total_img_area\n",
    "    )\n",
    "    layer_1_gridcell_contrib_ratio_to_total = (\n",
    "        torch.sum(flattened_layer_1_gridcell_contribs, dim=-1)\n",
    "        - layer_1_expected_region_contrib\n",
    "    ) / layer_1_expected_region_contrib\n",
    "\n",
    "    layer_2_expected_region_contrib = total_layer_2_output_contrib[:, None] * (\n",
    "        gridcell_area / total_img_area\n",
    "    )\n",
    "    layer_2_gridcell_contrib_ratio_to_total = (\n",
    "        torch.sum(flattened_layer_2_gridcell_contribs, dim=-1)\n",
    "        - layer_2_expected_region_contrib\n",
    "    ) / layer_2_expected_region_contrib\n",
    "\n",
    "    layer_3_expected_region_contrib = total_layer_3_output_contrib[:, None] * (\n",
    "        gridcell_area / total_img_area\n",
    "    )\n",
    "    layer_3_gridcell_contrib_ratio_to_total = (\n",
    "        torch.sum(flattened_layer_3_gridcell_contribs, dim=-1)\n",
    "        - layer_3_expected_region_contrib\n",
    "    ) / layer_3_expected_region_contrib\n",
    "\n",
    "    # Aggregate the maps and take per-pixel average\n",
    "    layer_1_to_gridcell_contribs = (\n",
    "        layer_1_to_gridcell_contribs.sum(dim=(3, 4)) / gridcell_area\n",
    "    )\n",
    "    layer_2_to_gridcell_contribs = (\n",
    "        layer_2_to_gridcell_contribs.sum(dim=(3, 4)) / gridcell_area\n",
    "    )\n",
    "    layer_3_to_gridcell_contribs = (\n",
    "        layer_3_to_gridcell_contribs.sum(dim=(3, 4)) / gridcell_area\n",
    "    )\n",
    "    layer_1_feature_vectors = layer_1_to_gridcell_contribs.view(\n",
    "        layer_1_to_gridcell_contribs.size(0), -1\n",
    "    )  # num_neurons x num_gridcells\n",
    "    layer_2_feature_vectors = layer_2_to_gridcell_contribs.view(\n",
    "        layer_2_to_gridcell_contribs.size(0), -1\n",
    "    )  # num_neurons x num_gridcells\n",
    "    layer_3_feature_vectors = layer_3_to_gridcell_contribs.view(\n",
    "        layer_3_to_gridcell_contribs.size(0), -1\n",
    "    )  # num_neurons x num_gridcells\n",
    "\n",
    "    return (\n",
    "        layer_1_feature_vectors,\n",
    "        layer_2_feature_vectors,\n",
    "        layer_3_feature_vectors,\n",
    "        layer_1_gridcell_contrib_ratio_to_total,\n",
    "        layer_2_gridcell_contrib_ratio_to_total,\n",
    "        layer_3_gridcell_contrib_ratio_to_total,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b16446f2-dfd4-4677-8014-25efc9068263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kmeans_clusters_in_rgb(image, num_clusters):\n",
    "    image_reshaped_rgb = image.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init=1, random_state=0).fit(\n",
    "        image_reshaped_rgb\n",
    "    )\n",
    "    rgb_cluster_map = kmeans.labels_.reshape(image.shape[0], image.shape[1])\n",
    "    return rgb_cluster_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04a0ac55-69da-4a09-ad7b-ab02b45827aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_cluster_contribs(\n",
    "    layer_1_output_contrib,\n",
    "    layer_2_output_contrib,\n",
    "    layer_3_output_contrib,\n",
    "    rgb_cluster_map,\n",
    "):\n",
    "    total_img_area = layer_1_output_contrib.size(-2) * layer_1_output_contrib.size(-1)\n",
    "    n_rgb_clusters = len(np.unique(rgb_cluster_map))\n",
    "    rgb_cluster_areas = torch.zeros(n_rgb_clusters)\n",
    "\n",
    "    # Maps for kernel to object contributions\n",
    "    num_layer_1_neurons = layer_1_output_contrib.shape[0]\n",
    "    num_layer_2_neurons = layer_2_output_contrib.shape[0]\n",
    "    num_layer_3_neurons = layer_3_output_contrib.shape[0]\n",
    "\n",
    "    layer_1_to_rgb_cluster_contribs = torch.zeros((num_layer_1_neurons, n_rgb_clusters))\n",
    "    layer_2_to_rgb_cluster_contribs = torch.zeros((num_layer_2_neurons, n_rgb_clusters))\n",
    "    layer_3_to_rgb_cluster_contribs = torch.zeros((num_layer_3_neurons, n_rgb_clusters))\n",
    "\n",
    "    layer_1_rgb_cluster_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_1_neurons, n_rgb_clusters)\n",
    "    )\n",
    "    layer_2_rgb_cluster_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_2_neurons, n_rgb_clusters)\n",
    "    )\n",
    "    layer_3_rgb_cluster_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_3_neurons, n_rgb_clusters)\n",
    "    )\n",
    "\n",
    "    total_layer_1_output_contrib = torch.sum(\n",
    "        torch.abs(layer_1_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_2_output_contrib = torch.sum(\n",
    "        torch.abs(layer_2_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_3_output_contrib = torch.sum(\n",
    "        torch.abs(layer_3_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "\n",
    "    for cluster_id in np.unique(rgb_cluster_map):\n",
    "\n",
    "        bimask = rgb_cluster_map == cluster_id\n",
    "        bimask = bimask.squeeze().astype(bool)\n",
    "        area = bimask.sum()\n",
    "\n",
    "        curr_rgb_cluster_layer_1_contribs = torch.abs(layer_1_output_contrib[:, bimask])\n",
    "        curr_rgb_cluster_layer_2_contribs = torch.abs(layer_2_output_contrib[:, bimask])\n",
    "        curr_rgb_cluster_layer_3_contribs = torch.abs(layer_3_output_contrib[:, bimask])\n",
    "\n",
    "        total_layer_1_spix_contrib = torch.sum(\n",
    "            curr_rgb_cluster_layer_1_contribs, dim=-1\n",
    "        )\n",
    "        total_layer_2_spix_contrib = torch.sum(\n",
    "            curr_rgb_cluster_layer_2_contribs, dim=-1\n",
    "        )\n",
    "        total_layer_3_spix_contrib = torch.sum(\n",
    "            curr_rgb_cluster_layer_3_contribs, dim=-1\n",
    "        )\n",
    "        avg_layer_1_contrib = total_layer_1_spix_contrib / area\n",
    "        avg_layer_2_contrib = total_layer_2_spix_contrib / area\n",
    "        avg_layer_3_contrib = total_layer_3_spix_contrib / area\n",
    "\n",
    "        # Store the average contribution from neurons of each layer to current rgb cluster\n",
    "        layer_1_to_rgb_cluster_contribs[:, cluster_id] = avg_layer_1_contrib.flatten()\n",
    "        layer_2_to_rgb_cluster_contribs[:, cluster_id] = avg_layer_2_contrib.flatten()\n",
    "        layer_3_to_rgb_cluster_contribs[:, cluster_id] = avg_layer_3_contrib.flatten()\n",
    "\n",
    "        # Compute deltas: ( actual contrib - expected contrib ) / expected contrib\n",
    "        layer_1_expected_rgb_cluster_contrib = total_layer_1_output_contrib * (\n",
    "            area / total_img_area\n",
    "        )\n",
    "        layer_1_rgb_cluster_contrib_ratio_to_total[:, cluster_id] = (\n",
    "            torch.abs(total_layer_1_spix_contrib - layer_1_expected_rgb_cluster_contrib)\n",
    "            / layer_1_expected_rgb_cluster_contrib\n",
    "        )\n",
    "        layer_2_expected_rgb_cluster_contrib = total_layer_2_output_contrib * (\n",
    "            area / total_img_area\n",
    "        )\n",
    "        layer_2_rgb_cluster_contrib_ratio_to_total[:, cluster_id] = (\n",
    "            torch.abs(total_layer_2_spix_contrib - layer_2_expected_rgb_cluster_contrib)\n",
    "            / layer_2_expected_rgb_cluster_contrib\n",
    "        )\n",
    "        layer_3_expected_rgb_cluster_contrib = total_layer_3_output_contrib * (\n",
    "            area / total_img_area\n",
    "        )\n",
    "        layer_3_rgb_cluster_contrib_ratio_to_total[:, cluster_id] = (\n",
    "            torch.abs(total_layer_3_spix_contrib - layer_3_expected_rgb_cluster_contrib)\n",
    "            / layer_3_expected_rgb_cluster_contrib\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        layer_1_to_rgb_cluster_contribs,\n",
    "        layer_2_to_rgb_cluster_contribs,\n",
    "        layer_3_to_rgb_cluster_contribs,\n",
    "        layer_1_rgb_cluster_contrib_ratio_to_total,\n",
    "        layer_2_rgb_cluster_contrib_ratio_to_total,\n",
    "        layer_3_rgb_cluster_contrib_ratio_to_total,\n",
    "        rgb_cluster_areas,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5398d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each gabor cluster - get average contrib, total contrib and total area\n",
    "def get_gabor_cluster_contribs(\n",
    "    layer_1_output_contrib,\n",
    "    layer_2_output_contrib,\n",
    "    layer_3_output_contrib,\n",
    "    gabor_cluster_map,\n",
    "):\n",
    "    total_img_area = layer_1_output_contrib.size(-2) * layer_1_output_contrib.size(-1)\n",
    "\n",
    "    num_layer_1_neurons = layer_1_output_contrib.shape[0]\n",
    "    num_layer_2_neurons = layer_2_output_contrib.shape[0]\n",
    "    num_layer_3_neurons = layer_3_output_contrib.shape[0]\n",
    "\n",
    "    n_gabor_clusters = len(np.unique(gabor_cluster_map))\n",
    "    layer_1_to_gabor_cluster_contribs = torch.zeros(\n",
    "        (num_layer_1_neurons, n_gabor_clusters)\n",
    "    )\n",
    "    layer_2_to_gabor_cluster_contribs = torch.zeros(\n",
    "        (num_layer_2_neurons, n_gabor_clusters)\n",
    "    )\n",
    "    layer_3_to_gabor_cluster_contribs = torch.zeros(\n",
    "        (num_layer_3_neurons, n_gabor_clusters)\n",
    "    )\n",
    "\n",
    "    gabor_cluster_areas = torch.zeros(n_gabor_clusters)\n",
    "    layer_1_gabor_cluster_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_1_neurons, n_gabor_clusters)\n",
    "    )\n",
    "    layer_2_gabor_cluster_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_2_neurons, n_gabor_clusters)\n",
    "    )\n",
    "    layer_3_gabor_cluster_contrib_ratio_to_total = torch.zeros(\n",
    "        (num_layer_3_neurons, n_gabor_clusters)\n",
    "    )\n",
    "\n",
    "    total_layer_1_output_contrib = torch.sum(\n",
    "        torch.abs(layer_1_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_2_output_contrib = torch.sum(\n",
    "        torch.abs(layer_2_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "    total_layer_3_output_contrib = torch.sum(\n",
    "        torch.abs(layer_3_output_contrib), dim=(1, 2)\n",
    "    )\n",
    "\n",
    "    for cluster_id in np.unique(gabor_cluster_map):\n",
    "\n",
    "        bimask = gabor_cluster_map == cluster_id\n",
    "        bimask = bimask.squeeze().astype(bool)\n",
    "        area = bimask.sum()\n",
    "\n",
    "        curr_gabor_cluster_layer_1_contribs = torch.abs(\n",
    "            layer_1_output_contrib[:, bimask]\n",
    "        )\n",
    "        curr_gabor_cluster_layer_2_contribs = torch.abs(\n",
    "            layer_2_output_contrib[:, bimask]\n",
    "        )\n",
    "        curr_gabor_cluster_layer_3_contribs = torch.abs(\n",
    "            layer_3_output_contrib[:, bimask]\n",
    "        )\n",
    "\n",
    "        total_layer_1_gabor_clust_contrib = torch.sum(\n",
    "            curr_gabor_cluster_layer_1_contribs, dim=-1\n",
    "        )\n",
    "        total_layer_2_gabor_clust_contrib = torch.sum(\n",
    "            curr_gabor_cluster_layer_2_contribs, dim=-1\n",
    "        )\n",
    "        total_layer_3_gabor_clust_contrib = torch.sum(\n",
    "            curr_gabor_cluster_layer_3_contribs, dim=-1\n",
    "        )\n",
    "        avg_layer_1_contrib = total_layer_1_gabor_clust_contrib / area\n",
    "        avg_layer_2_contrib = total_layer_2_gabor_clust_contrib / area\n",
    "        avg_layer_3_contrib = total_layer_3_gabor_clust_contrib / area\n",
    "\n",
    "        # Store the average contribution from each layer neurons to current gabor cluster\n",
    "        layer_1_to_gabor_cluster_contribs[:, cluster_id] = avg_layer_1_contrib.flatten()\n",
    "        layer_2_to_gabor_cluster_contribs[:, cluster_id] = avg_layer_2_contrib.flatten()\n",
    "        layer_3_to_gabor_cluster_contribs[:, cluster_id] = avg_layer_3_contrib.flatten()\n",
    "\n",
    "        # Compute deltas: (actual contrib - expected contrib) / expected contrib\n",
    "        layer_1_expected_gabor_cluster_contrib = total_layer_1_output_contrib * (area / total_img_area)\n",
    "        layer_1_gabor_cluster_contrib_ratio_to_total[:, cluster_id] = (\n",
    "            torch.abs(\n",
    "                total_layer_1_gabor_clust_contrib\n",
    "                - layer_1_expected_gabor_cluster_contrib\n",
    "            )\n",
    "            / layer_1_expected_gabor_cluster_contrib\n",
    "        )\n",
    "        layer_2_expected_gabor_cluster_contrib = total_layer_2_output_contrib * (area / total_img_area)\n",
    "        layer_2_gabor_cluster_contrib_ratio_to_total[:, cluster_id] = (\n",
    "            torch.abs(\n",
    "                total_layer_2_gabor_clust_contrib\n",
    "                - layer_2_expected_gabor_cluster_contrib\n",
    "            )\n",
    "            / layer_2_expected_gabor_cluster_contrib\n",
    "        )\n",
    "        layer_3_expected_gabor_cluster_contrib = total_layer_3_output_contrib * (area / total_img_area)\n",
    "        layer_3_gabor_cluster_contrib_ratio_to_total[:, cluster_id] = (\n",
    "            torch.abs(\n",
    "                total_layer_3_gabor_clust_contrib\n",
    "                - layer_3_expected_gabor_cluster_contrib\n",
    "            )\n",
    "            / layer_3_expected_gabor_cluster_contrib\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        layer_1_to_gabor_cluster_contribs,\n",
    "        layer_2_to_gabor_cluster_contribs,\n",
    "        layer_3_to_gabor_cluster_contribs,\n",
    "        layer_1_gabor_cluster_contrib_ratio_to_total,\n",
    "        layer_2_gabor_cluster_contrib_ratio_to_total,\n",
    "        layer_3_gabor_cluster_contrib_ratio_to_total,\n",
    "        gabor_cluster_areas,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bb43de8-648e-4961-a723-b8d8bdb94980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inference_results(\n",
    "    single_image_dataloader,\n",
    "    ffn_model,\n",
    "    cfg,\n",
    "    categories_dict,\n",
    "    num_rgb_clusters,\n",
    "    num_gabor_clusters,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(single_image_dataloader))\n",
    "\n",
    "    data = batch[\"data\"].cuda()\n",
    "    N, C, H, W = data.shape\n",
    "    annotations = convert_annotations_to_numpy(batch[\"annotations\"])\n",
    "    annotations = add_other_annotation(annotations)\n",
    "\n",
    "    features = batch[\"features\"].squeeze().cuda()\n",
    "    features_shape = batch[\"features_shape\"].squeeze().tolist()\n",
    "    reshape = True\n",
    "\n",
    "    proc = data_process.DataProcessor(cfg.data, device=\"cpu\")\n",
    "    x = batch[\"data\"]\n",
    "    coords = proc.get_coordinates(\n",
    "        data_shape=features_shape,\n",
    "        patch_shape=cfg.data.patch_shape,\n",
    "        split=cfg.data.coord_split,\n",
    "        normalize_range=cfg.data.coord_normalize_range,\n",
    "    )\n",
    "    coords = coords.to(x).cuda()\n",
    "\n",
    "    inference_results = {}\n",
    "    with torch.no_grad():\n",
    "        out = ffn_model(coords, img=data)\n",
    "        pred = out[\"predicted\"]\n",
    "        intermediate_results = out[\"intermediate_results\"]\n",
    "\n",
    "        if reshape:\n",
    "            # This reshapes the prediction into an image\n",
    "            pred = proc.process_outputs(\n",
    "                pred,\n",
    "                input_img_shape=batch[\"data_shape\"].squeeze().tolist(),\n",
    "                features_shape=features_shape,\n",
    "                patch_shape=cfg.data.patch_shape,\n",
    "            )\n",
    "\n",
    "    image_numpy = data[0].permute(1, 2, 0).cpu().numpy()\n",
    "    rgb_cluster_map = compute_kmeans_clusters_in_rgb(image_numpy, num_rgb_clusters)\n",
    "\n",
    "    # Compute Gabor clusters map\n",
    "    image_pil_format = (\n",
    "        (data[0].clamp(0, 1) * 255).permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    )\n",
    "    gabor_cluster_map = get_gabor_label_map(image_pil_format, num_gabor_clusters)\n",
    "\n",
    "    inference_results = {\n",
    "        \"data\": batch[\"data\"],\n",
    "        \"pred\": pred,\n",
    "        \"annotations\": annotations,\n",
    "        \"img_hw\": (H, W),\n",
    "        \"intermediate_results\": intermediate_results,\n",
    "        \"rgb_cluster_map\": rgb_cluster_map,\n",
    "        \"gabor_cluster_map\": gabor_cluster_map,\n",
    "    }\n",
    "\n",
    "    categories_in_frame = {}\n",
    "    for ann in annotations:\n",
    "        if ann[\"category_id\"] not in categories_in_frame:\n",
    "            categories_in_frame[ann[\"category_id\"]] = categories_dict[\n",
    "                ann[\"category_id\"]\n",
    "            ]\n",
    "\n",
    "    categories_in_frame[-1] = categories_dict[-1]\n",
    "    object_categories = [v[\"name\"] for k, v in categories_in_frame.items()]\n",
    "    categories_in_frame = [v for k, v in categories_in_frame.items()]\n",
    "\n",
    "    return inference_results, categories_in_frame, object_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d4fdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_variables_for_image(\n",
    "    inference_results,\n",
    "    ffn_model,\n",
    "    instance_to_ann_id_map,\n",
    "    cell_stride_h,\n",
    "    cell_stride_w,\n",
    "    instance_names,\n",
    "):\n",
    "    intermediate_results = inference_results[\"intermediate_results\"]\n",
    "    (H, W) = inference_results[\"img_hw\"]\n",
    "    annotations = inference_results[\"annotations\"]\n",
    "\n",
    "    all_variables_for_image = {}\n",
    "\n",
    "    intermediate_results = inference_results[\"intermediate_results\"]\n",
    "\n",
    "    rgb_cluster_map = inference_results[\"rgb_cluster_map\"]\n",
    "    gabor_cluster_map = inference_results[\"gabor_cluster_map\"]\n",
    "\n",
    "    # Get model contributions\n",
    "    compute_contrib_obj = ComputeMLPContributions(\n",
    "        ffn_model, intermediate_results, (H, W)\n",
    "    )\n",
    "\n",
    "    layer_1_output_contrib, layer_2_output_contrib, layer_3_output_contrib, _, _, _ = (\n",
    "        compute_contrib_obj.compute_all_layer_mappings()\n",
    "    )\n",
    "\n",
    "    # Get contributions clustered by each entity type and normalize them.\n",
    "    # Additionally, obtain variances within instance.\n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        layer_1_instance_contrib_ratio_to_total,\n",
    "        layer_2_instance_contrib_ratio_to_total,\n",
    "        layer_3_instance_contrib_ratio_to_total,\n",
    "        instance_areas,\n",
    "    ) = get_instance_contribs(\n",
    "        layer_1_output_contrib,\n",
    "        layer_2_output_contrib,\n",
    "        layer_3_output_contrib,\n",
    "        annotations,\n",
    "        instance_to_ann_id_map,\n",
    "        instance_names,\n",
    "    )\n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        layer_1_gridcell_contrib_ratio_to_total,\n",
    "        layer_2_gridcell_contrib_ratio_to_total,\n",
    "        layer_3_gridcell_contrib_ratio_to_total,\n",
    "    ) = get_gridcell_contribs(\n",
    "        layer_1_output_contrib,\n",
    "        layer_2_output_contrib,\n",
    "        layer_3_output_contrib,\n",
    "        cell_stride_h,\n",
    "        cell_stride_w,\n",
    "    )\n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        layer_1_rgb_cluster_contrib_ratio_to_total,\n",
    "        layer_2_rgb_cluster_contrib_ratio_to_total,\n",
    "        layer_3_rgb_cluster_contrib_ratio_to_total,\n",
    "        rgb_cluster_areas,\n",
    "    ) = get_rgb_cluster_contribs(\n",
    "        layer_1_output_contrib,\n",
    "        layer_2_output_contrib,\n",
    "        layer_3_output_contrib,\n",
    "        rgb_cluster_map,\n",
    "    )\n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        layer_1_gabor_cluster_contrib_ratio_to_total,\n",
    "        layer_2_gabor_cluster_contrib_ratio_to_total,\n",
    "        layer_3_gabor_cluster_contrib_ratio_to_total,\n",
    "        gabor_cluster_areas,\n",
    "    ) = get_gabor_cluster_contribs(\n",
    "        layer_1_output_contrib,\n",
    "        layer_2_output_contrib,\n",
    "        layer_3_output_contrib,\n",
    "        gabor_cluster_map,\n",
    "    )\n",
    "\n",
    "    # Some of the neurons in MLP are dead (all 0 contributions). These are removed in normalization\n",
    "    all_variables_for_image = {\n",
    "        \"layer_1_output_contrib\": torch.abs(layer_1_output_contrib),\n",
    "        \"layer_2_output_contrib\": torch.abs(layer_2_output_contrib),\n",
    "        \"layer_3_output_contrib\": torch.abs(layer_3_output_contrib),\n",
    "        # areas\n",
    "        \"instance_areas\": instance_areas,\n",
    "        \"rgb_cluster_areas\": rgb_cluster_areas,\n",
    "        \"gabor_cluster_areas\": gabor_cluster_areas,\n",
    "        # per-patch contribution ratios\n",
    "        \"layer_3_instance_contrib_ratio_to_total\": layer_3_instance_contrib_ratio_to_total,\n",
    "        \"layer_2_instance_contrib_ratio_to_total\": layer_2_instance_contrib_ratio_to_total,\n",
    "        \"layer_1_instance_contrib_ratio_to_total\": layer_1_instance_contrib_ratio_to_total,\n",
    "        \"layer_3_gridcell_contrib_ratio_to_total\": layer_3_gridcell_contrib_ratio_to_total,\n",
    "        \"layer_2_gridcell_contrib_ratio_to_total\": layer_2_gridcell_contrib_ratio_to_total,\n",
    "        \"layer_1_gridcell_contrib_ratio_to_total\": layer_1_gridcell_contrib_ratio_to_total,\n",
    "        \"layer_3_rgb_cluster_contrib_ratio_to_total\": layer_3_rgb_cluster_contrib_ratio_to_total,\n",
    "        \"layer_2_rgb_cluster_contrib_ratio_to_total\": layer_2_rgb_cluster_contrib_ratio_to_total,\n",
    "        \"layer_1_rgb_cluster_contrib_ratio_to_total\": layer_1_rgb_cluster_contrib_ratio_to_total,\n",
    "        \"layer_3_gabor_cluster_contrib_ratio_to_total\": layer_3_gabor_cluster_contrib_ratio_to_total,\n",
    "        \"layer_2_gabor_cluster_contrib_ratio_to_total\": layer_2_gabor_cluster_contrib_ratio_to_total,\n",
    "        \"layer_1_gabor_cluster_contrib_ratio_to_total\": layer_1_gabor_cluster_contrib_ratio_to_total,\n",
    "        \"num_instances_in_frame\": len(instance_areas),\n",
    "    }\n",
    "\n",
    "    return all_variables_for_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd8a82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_variance_of_deltas(all_variables_for_image, num_rgb_clusters, cell_stride_h, cell_stride_w):\n",
    "\n",
    "    num_instances_in_frame = all_variables_for_image[\"num_instances_in_frame\"]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 8), tight_layout=True)\n",
    "\n",
    "    layer_3_instance_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_3_instance_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_3_gridcell_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_3_gridcell_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_3_rgb_cluster_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_3_rgb_cluster_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_3_gabor_cluster_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_3_gabor_cluster_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "\n",
    "    layer_2_instance_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_2_instance_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_2_gridcell_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_2_gridcell_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_2_rgb_cluster_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_2_rgb_cluster_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_2_gabor_cluster_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_2_gabor_cluster_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "\n",
    "    layer_1_instance_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_1_instance_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_1_gridcell_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_1_gridcell_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_1_rgb_cluster_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_1_rgb_cluster_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "    layer_1_gabor_cluster_variances = torch.var(\n",
    "        all_variables_for_image[\"layer_1_gabor_cluster_contrib_ratio_to_total\"], dim=-1\n",
    "    )\n",
    "\n",
    "    sorted_variance_layer_3_instance_contrib_ratio, layer_3_instance_sorted_indices = torch.sort(layer_3_instance_variances)\n",
    "    sorted_variance_layer_3_gridcell_contrib_ratio, layer_3_gridcell_sorted_indices = torch.sort(layer_3_gridcell_variances)\n",
    "    sorted_variance_layer_3_rgb_cluster_contrib_ratio, layer_3_rgb_cluster_sorted_indices = torch.sort(layer_3_rgb_cluster_variances)\n",
    "    sorted_variance_layer_3_gabor_cluster_contrib_ratio, layer_3_gabor_cluster_sorted_indices = torch.sort(layer_3_gabor_cluster_variances)\n",
    "    \n",
    "    sorted_variance_layer_2_instance_contrib_ratio, layer_2_instance_sorted_indices = torch.sort(layer_2_instance_variances)\n",
    "    sorted_variance_layer_2_gridcell_contrib_ratio, layer_2_gridcell_sorted_indices = torch.sort(layer_2_gridcell_variances)\n",
    "    sorted_variance_layer_2_rgb_cluster_contrib_ratio, layer_2_rgb_cluster_sorted_indices = torch.sort(layer_2_rgb_cluster_variances)\n",
    "    sorted_variance_layer_2_gabor_cluster_contrib_ratio, layer_2_gabor_cluster_sorted_indices = torch.sort(layer_2_gabor_cluster_variances)\n",
    "\n",
    "    sorted_variance_layer_1_instance_contrib_ratio, layer_1_instance_sorted_indices = torch.sort(layer_1_instance_variances)\n",
    "    sorted_variance_layer_1_gridcell_contrib_ratio, layer_1_gridcell_sorted_indices = torch.sort(layer_1_gridcell_variances)\n",
    "    sorted_variance_layer_1_rgb_cluster_contrib_ratio, layer_1_rgb_cluster_sorted_indices = torch.sort(layer_1_rgb_cluster_variances)\n",
    "    sorted_variance_layer_1_gabor_cluster_contrib_ratio, layer_1_gabor_cluster_sorted_indices = torch.sort(layer_1_gabor_cluster_variances)\n",
    "\n",
    "    labels = [\"Instances variance\", \"Grid cells variance\", \"RGB Cluster variance\", \"Gabor Cluster variance\"]\n",
    "    colors = [\"r\", \"g\", \"b\", \"m\"]\n",
    "\n",
    "    # Plot layer 3\n",
    "    for idx, var in enumerate(\n",
    "        [\n",
    "            sorted_variance_layer_3_instance_contrib_ratio,\n",
    "            sorted_variance_layer_3_gridcell_contrib_ratio,\n",
    "            sorted_variance_layer_3_rgb_cluster_contrib_ratio,\n",
    "            sorted_variance_layer_3_gabor_cluster_contrib_ratio,\n",
    "        ]\n",
    "    ):\n",
    "        axs[0].plot(var, label=labels[idx], c=colors[idx])\n",
    "    axs[0].set_title(f\"Layer 3\")\n",
    "\n",
    "    # Plot layer 2\n",
    "    for idx, var in enumerate(\n",
    "        [\n",
    "            sorted_variance_layer_2_instance_contrib_ratio,\n",
    "            sorted_variance_layer_2_gridcell_contrib_ratio,\n",
    "            sorted_variance_layer_2_rgb_cluster_contrib_ratio,\n",
    "            sorted_variance_layer_2_gabor_cluster_contrib_ratio,\n",
    "        ]\n",
    "    ):\n",
    "        axs[1].plot(var, label=labels[idx], c=colors[idx])\n",
    "    axs[1].set_title(f\"Layer 2\")\n",
    "\n",
    "    # Plot layer 1\n",
    "    for idx, var in enumerate(\n",
    "        [\n",
    "            sorted_variance_layer_1_instance_contrib_ratio,\n",
    "            sorted_variance_layer_1_gridcell_contrib_ratio,\n",
    "            sorted_variance_layer_1_rgb_cluster_contrib_ratio,\n",
    "            sorted_variance_layer_1_gabor_cluster_contrib_ratio,\n",
    "        ]\n",
    "    ):\n",
    "        axs[2].plot(var, label=labels[idx], c=colors[idx])\n",
    "    axs[2].set_title(f\"Layer 1\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"num_inst={num_instances_in_frame}, num_rgb_clust={num_rgb_clusters}, num_cells={cell_stride_h*cell_stride_w}\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    # Every subplot has the same legend, let us pick one\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"upper center\", ncol=6, bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "    sorted_deltas_dict = {\n",
    "        \"layer_1\": {\n",
    "            \"instances_deltas\": sorted_variance_layer_1_instance_contrib_ratio,\n",
    "            \"gridcells_deltas\": sorted_variance_layer_1_gridcell_contrib_ratio,\n",
    "            \"rgb_clusters_deltas\": sorted_variance_layer_1_rgb_cluster_contrib_ratio,\n",
    "            \"gabor_clusters_deltas\": sorted_variance_layer_1_gabor_cluster_contrib_ratio,\n",
    "        },\n",
    "        \"layer_2\": {\n",
    "            \"instances_deltas\": sorted_variance_layer_2_instance_contrib_ratio,\n",
    "            \"gridcells_deltas\": sorted_variance_layer_2_gridcell_contrib_ratio,\n",
    "            \"rgb_clusters_deltas\": sorted_variance_layer_2_rgb_cluster_contrib_ratio,\n",
    "            \"gabor_clusters_deltas\": sorted_variance_layer_2_gabor_cluster_contrib_ratio,\n",
    "        },\n",
    "        \"layer_3\": {\n",
    "            \"instances_deltas\": sorted_variance_layer_3_instance_contrib_ratio,\n",
    "            \"gridcells_deltas\": sorted_variance_layer_3_gridcell_contrib_ratio,\n",
    "            \"rgb_clusters_deltas\": sorted_variance_layer_3_rgb_cluster_contrib_ratio,\n",
    "            \"gabor_clusters_deltas\": sorted_variance_layer_3_gabor_cluster_contrib_ratio,\n",
    "        },\n",
    "        \"sorted_indices\": {\n",
    "            \"layer_1\": {\n",
    "                \"instances\": layer_1_instance_sorted_indices,\n",
    "                \"gridcells\": layer_1_gridcell_sorted_indices,\n",
    "                \"rgb_clusters\": layer_1_rgb_cluster_sorted_indices,\n",
    "                \"gabor_clusters\": layer_1_gabor_cluster_sorted_indices,\n",
    "            },\n",
    "            \"layer_2\": {\n",
    "                \"instances\": layer_2_instance_sorted_indices,\n",
    "                \"gridcells\": layer_2_gridcell_sorted_indices,\n",
    "                \"rgb_clusters\": layer_2_rgb_cluster_sorted_indices,\n",
    "                \"gabor_clusters\": layer_2_gabor_cluster_sorted_indices,\n",
    "            },\n",
    "            \"layer_3\": {\n",
    "                \"instances\": layer_3_instance_sorted_indices,\n",
    "                \"gridcells\": layer_3_gridcell_sorted_indices,\n",
    "                \"rgb_clusters\": layer_3_rgb_cluster_sorted_indices,\n",
    "                \"gabor_clusters\": layer_3_gabor_cluster_sorted_indices,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return sorted_deltas_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed99b0-4275-41bc-a730-b8a53449219c",
   "metadata": {},
   "source": [
    "Analyze each image and save the raw values for downstream visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc078181",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_vid_patch_deltas_var_dict = {}\n",
    "\n",
    "# Cluster settings\n",
    "num_rgb_and_gabor_clusters_dict = {\"0005\": 32, \"26_cblDl5vCZnw\": 24}\n",
    "cell_stride_h_dict = {\"0005\": 4, \"26_cblDl5vCZnw\": 4}\n",
    "cell_stride_w_dict = {\"0005\": 8, \"26_cblDl5vCZnw\": 6}\n",
    "\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for vidname in vidnames[dataset_name]:\n",
    "        single_image_dataloader = dataloader_dict[dataset_name][vidname]\n",
    "        ffn_model = ffn_models_dict[dataset_name][vidname]\n",
    "        categories_dict = categories_dicts[dataset_name][vidname]\n",
    "        cfg = cfg_dict[dataset_name][vidname]\n",
    "\n",
    "        categories = list(categories_dict.values())\n",
    "\n",
    "        num_rgb_clusters = num_rgb_and_gabor_clusters_dict[vidname]\n",
    "        num_gabor_clusters = num_rgb_and_gabor_clusters_dict[vidname]\n",
    "        cell_stride_h, cell_stride_w = (\n",
    "            cell_stride_h_dict[vidname],\n",
    "            cell_stride_w_dict[vidname],\n",
    "        )\n",
    "\n",
    "        inference_results, categories_in_frame, object_categories = (\n",
    "            compute_inference_results(\n",
    "                single_image_dataloader,\n",
    "                ffn_model,\n",
    "                cfg,\n",
    "                categories_dict,\n",
    "                num_rgb_clusters,\n",
    "                num_gabor_clusters,\n",
    "            )\n",
    "        )\n",
    "        (\n",
    "            inst_id_to_cat_and_inst_suffix,\n",
    "            instance_to_ann_id_map,\n",
    "            instance_names,\n",
    "            object_to_instances_map,\n",
    "            obj_to_obj_name_idx,\n",
    "            instance_names,\n",
    "        ) = get_instance_info(inference_results, object_categories, categories)\n",
    "\n",
    "        all_variables_for_image = compute_all_variables_for_image(\n",
    "            inference_results,\n",
    "            ffn_model,\n",
    "            instance_to_ann_id_map,\n",
    "            cell_stride_h,\n",
    "            cell_stride_w,\n",
    "            instance_names,\n",
    "        )\n",
    "\n",
    "        sorted_deltas_dict = compute_variance_of_deltas(all_variables_for_image, num_rgb_clusters, cell_stride_h, cell_stride_w)\n",
    "\n",
    "        per_vid_patch_deltas_var_dict[vidname] = {\n",
    "            \"sorted_deltas_dict\": sorted_deltas_dict,\n",
    "            \"cluster_info\": {\n",
    "                \"num_instances\": all_variables_for_image[\"num_instances_in_frame\"],\n",
    "                \"num_rgb_clusters\": num_rgb_clusters,\n",
    "                \"num_gabor_clusters\": num_gabor_clusters,\n",
    "                \"cell_stride_h\": cell_stride_h,\n",
    "                \"cell_stride_w\": cell_stride_w,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_dir = \"../analysis_data/MLP/contributions_to_objects\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(save_dir, f\"per_vid_patch_deltas_var_dict.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(per_vid_patch_deltas_var_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
